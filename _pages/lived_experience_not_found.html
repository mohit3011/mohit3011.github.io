---
layout: archive
title: ""
permalink: /lived_experience_not_found_blog/
author_profile: true
---


<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ADR Paper Blog</title>
    <!-- Font Awesome for icons -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0-beta3/css/all.min.css">
    <!-- Google Fonts -->
    <link href="https://fonts.googleapis.com/css2?family=Roboto:wght@400;500;700&display=swap" rel="stylesheet">
    <!-- Bulma CSS Framework -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/bulma/0.9.3/css/bulma.min.css">
    <style>
        body {
            font-family: 'Roboto', sans-serif;
            color: #363636;
        }

        .container {
            box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
            border-radius: 8px;
            padding: 20px;
            margin-top: 20px;
            max-width: 1200px;
            margin: 0 auto;
            width: 90%;
        }

        h1, h2, h3 {
            color: #2e2e2e;
            margin-bottom: 15px;
        }

        h1 {
            font-size: clamp(1.5rem, 4vw, 2rem);
            font-weight: 700;
            text-align: center;
            margin: 2rem 0;
            line-height: 1.4;
            color: #2e2e2e;
            padding: 0 1rem;
        }

        p, a {
            font-size: 1rem;
            line-height: 1.8;
        }

        a {
            color: #3273dc;
            text-decoration: none;
            font-weight: 500;
        }

        a:hover {
            text-decoration: underline;
        }

        .authors, .links {
            margin: 20px 0;
            padding: 15px;
            border-left: 5px solid #3273dc;
            border-radius: 4px;
        }

        .authors h3, .links h3 {
            margin-bottom: 10px;
        }

        .links ul {
            list-style-type: none;
        }

        .links li {
            margin-bottom: 8px;
        }

        .buttons {
            display: flex;
            justify-content: center;
            gap: 15px;
            margin-top: 20px;
            flex-direction: row;
            flex-wrap: wrap;
            padding: 0 1rem;
        }

        .button {
            display: flex;
            align-items: center;
            justify-content: center;
            padding: 10px 20px;
            border-radius: 5px;
            text-decoration: none;
            font-weight: 500;
            color: #fff;
            font-size: 1rem;
            box-shadow: 0 2px 5px rgba(0, 0, 0, 0.2);
            transition: background-color 0.3s ease;
            white-space: nowrap;
            margin: 5px;
        }

        .button.arxiv {
            background-color: #B31B1B;
        }

        .button.github {
            background-color: #333;
        }

        .button img {
            margin-right: 10px;
            width: 20px;
            height: 20px;
        }

        .button:hover {
            opacity: 0.9;
        }

        footer {
            text-align: center;
            margin-top: 40px;
            font-size: 0.9rem;
        }

        .authors {
            margin: 2rem clamp(0.5rem, 3vw, 2rem);
            padding: 1.5rem clamp(1rem, 3vw, 1.5rem);
            background-color: #f8f9fa;
            border-radius: 8px;
            border-left: none;
        }

        .author-list {
            margin-bottom: 1rem;
            line-height: 1.6;
            font-size: clamp(0.9rem, 2.5vw, 1rem);
        }

        .author-name {
            color: #2a2a2a;
            text-decoration: none;
            transition: color 0.2s ease;
        }

        .author-name:hover {
            color: #3273dc;
            text-decoration: none;
        }

        .affiliations {
            font-size: clamp(0.8rem, 2vw, 0.9rem);
            color: #666;
            line-height: 1.4;
        }

        .affiliation {
            display: inline-block;
            margin-right: 0.5rem;
        }

        .affiliation sup {
            color: #3273dc;
            font-weight: 500;
        }

        h2 {
            font-size: 1.75rem;
            font-weight: 600;
            color: #2e2e2e;
            margin-top: 2.5rem;
            margin-bottom: 1.5rem;
            padding-bottom: 0.5rem;
            border-top: 2px solid #eaeaea;
        }

        .figure {
            width: min(90%, 800px);
            padding: 0 1rem;
        }

        /* Media Queries */
        @media screen and (max-width: 768px) {
            .buttons {
                flex-direction: column;
                align-items: stretch;
            }

            .button {
                width: 100%;
                margin: 5px 0;
            }

            .figure {
                width: 100%;
            }

            .affiliations p {
                display: flex;
                flex-direction: column;
                gap: 0.5rem;
            }

            .affiliation {
                display: block;
            }

            /* Hide the separator on mobile */
            .affiliations span.affiliation + span::before {
                display: none;
            }
        }

        @media screen and (max-width: 480px) {
            .author-list p {
                display: flex;
                flex-direction: column;
                gap: 0.5rem;
            }

            .author-list a::after {
                content: ',';
                display: none;
            }
        }

        h3 {
            font-size: 1.25rem;
            font-weight: 600;
            color: #2e2e2e;
            margin-top: 2rem;
            margin-bottom: 1rem;
            line-height: 1.4;
        }

        h3:contains("Finding") {
            color: #3273dc;
            font-weight: 500;
        }
    </style>
</head>
<body>

    <!-- Main Content -->
    <div>
        <h1><i>Lived Experience Not Found:</i> LLMs Struggle to Align with Experts on Addressing Adverse Drug Reactions</h1>
        
        <div class="authors">
            <h3>Authors</h3>
            <div class="author-list">
                <p>
                    <a href="#" class="author-name">Mohit Chandra</a><sup>1</sup>, 
                    <a href="#" class="author-name">Siddharth Sriraman</a><sup>1</sup>, 
                    <a href="#" class="author-name">Gaurav Verma</a><sup>1</sup>, 
                    <a href="#" class="author-name">Harneet Singh Khanuja</a><sup>1</sup>, 
                    <a href="#" class="author-name">Jose Suarez Campayo</a><sup>2</sup>, 
                    <a href="#" class="author-name">Zihang Li</a><sup>3</sup>, 
                    <a href="#" class="author-name">Michael L. Birnbaum</a><sup>4</sup>, 
                    <a href="#" class="author-name">Munmun De Choudhury</a><sup>1</sup>
                </p>
            </div>
            <div class="affiliations">
                <p><span class="affiliation"><sup>1</sup>College of Computing, Georgia Institute of Technology</span> | 
                   <span class="affiliation"><sup>2</sup>Hospital General Universitario Gregorio Marañón</span> | 
                   <span class="affiliation"><sup>3</sup>Hofstra University</span> | 
                   <span class="affiliation"><sup>4</sup>Columbia University</span></p>
            </div>
        </div>
        
        <div>
            <div class="buttons">
                <a href="https://arxiv.org/abs/2310.13132" target="_blank" class="button arxiv">
                    <i class="fas fa-file-pdf"></i>
                    Paper on arXiv
                </a>
                <a href="https://github.com/claws-lab/XLingEval" target="_blank" class="button github">
                    <i class="fab fa-github"></i>
                    Code Repository
                </a>
            </div>
        </div>

        <h2>Introduction</h2>
        <div>
            <figure class="figure" style="width: 100%; text-align: center;">
                <img src="../images/adr_paper_blog/figure_1.png" alt="Overview of work; we present two tasks in this work– ADR detection and multiclass classification (RQ1), and Expert-LLM response alignment (RQ2)." style="width: 40%; margin: 0 auto; display: block;" />
                <figcaption>Figure 1: Overview of work; we present two tasks in this work– ADR detection and multiclass classification (RQ1), and Expert-LLM response alignment (RQ2).</figcaption>
            </figure>
            <br>
            <p>Adverse Drug Reactions (ADRs) from psychiatric medications are one of the leading causes of hospitalizations among mental health patients. With healthcare systems and online communities facing limitations in resolving ADR-related issues, Large Language Models (LLMs) have the potential to fill this gap. However, despite the increasing capabilities of LLMs, past research has not explored their capabilities in detecting ADRs related to psychiatric medications or in providing effective harm reduction strategies. To address this, in this work, we introduce the Psych-ADR benchmark and the Adverse Drug Reaction Response Assessment (ADRA) framework to systematically evaluate LLM performance in detecting ADR expressions and delivering expert-aligned mitigation strategies. The proposed Psych-ADR benchmark includes 239 Reddit posts, labeled across two hierarchical levels for ADR detection and multiclass classification along with expert-written responses to queries. The proposed framework evaluates LLM-generated responses against those of medical experts, focusing on four assessment axes: (a) text readability, (b) emotion and tone expression, (c) alignment of harm-reduction strategies, and (d) actionability of suggested strategies.</p>
        </div>

        <h2>Psych-ADR Benchmark</h2>

        <div>
            <figure class="figure" style="width: 100%; text-align: center;">
                <img src="../images/adr_paper_blog/figure_2.png" alt="Figure 2: (Left)Class-wise distribution of examples in thePsych-ADR benchmark dataset; % w.r.t. N = 239. (Right) Sample answer representing the structure of answers provided in the Psych-ADR benchmark dataset." style="width: 60%; margin: 0 auto; display: block;" />
                <figcaption>Figure 2: (Left)Class-wise distribution of examples in thePsych-ADR benchmark dataset; % w.r.t. N = 239. (Right) Sample answer representing the structure of answers provided in the Psych-ADR benchmark dataset.</figcaption>
            </figure>
            <br>
            <p>Psych-ADR benchmark is a novel dataset with 239 reddit posts related to psychiatric medications and symptoms with annotations and replies provided by medical experts. The dataset contains two-hierarchical labels depicting -- 1) Presence/Absence of ADR, 2) Category of ADR. A key aspect of the Psych-ADR benchmark is the inclusion of expert-written responses to queries in the ADR labeled posts. We identified and articulated the logical structure where each response in our dataset begins with empathizing with the patient, followed by information on diagnosis, request for additional information, proposing harm reduction strategies to mitigate the ADR, and concluding with a final set of questions.</p>
        </div>

        <h2>ADRA Alignment Framework</h2>

        <div>
            <p>Evaluation of long-form text generation is an open problem and involves many challenges like isolating the stylistics from the semantics. However, in the context of responses to ADR queries, we propose abstracting out the LLM generations and ground-truth expert responses to four key components– (1) emotion and tone, (2) text readability, (3) harm reduction strategy, and (4) actionability of proposed strategies. Via this abstraction to key components, our alignment evaluations focus on specific aspects that contribute towards an ideal response to ADR queries.</p>
            <br>
            <ul style="margin-left: 40px;">
                <li><b>Emotion and Tone Alignment</b>: We measured the alignment of LLM-generated and expert written answers across 8 relevant emotional and tonal categories identified from prior literature.</li>
                <br>
                <li><b>Readability Alignment</b>: To evaluate the difficulty level of reading both LLM-generated content and expert-written text, we employed the SMOG Index—a widely recognized measure commonly used to assess health literacy materials.</li>
                <br>
                <li><b>Harm Reduction Strategy Alignment</b>: In cases of adverse reactions to psychiatric medications, suggesting safe medical interventions is crucial to prevent further harm. We operationalized these interventions using harm reduction strategies (HRS), aimed at minimizing the negative effects of medications that one is reliant on. Ideally, LLMs should propose strategies that align with the expert's responses.</li>
                <br>
                <li><b>Actionability of Proposed Strategies</b>: Actionability in the responses of healthcare professionals enables greater engagement and encourages increased action from patients. To this end, we designed an approach to measure the alignment between LLM responses and expert responses along the actionability dimension using four (4) sub-criteria.</li>
            </ul>
        </div>

        <h2>Findings</h2>

        <div>
            <figure class="figure" style="width: 100%; text-align: center;">
                <img src="../images/adr_paper_blog/figure_3.png" alt="Table 1: Performance of different models on Binary Detection and Multiclass Classification tasks under Zero-Shot and 5-Shot scenarios. We report the accuracy score(Acc.) and weighted F1 score as(F1) with the best and second-best performing model metrics in each scenario highlighted in bold and underline, respectively." style="width: 60%; margin: 0 auto; display: block;" />
                <figcaption>Table 1: Performance of different models on Binary Detection and Multiclass Classification tasks under Zero-Shot and 5-Shot scenarios. We report the accuracy score(Acc.) and weighted F1 score as(F1) with the best and second-best performing model metrics in each scenario highlighted in bold and underline, respectively.</figcaption>
            </figure>
        </div>

        <h3>Finding 1: Larger models typically perform better for ADR detection tasks,but this trend does not hold for ADR multiclass classification</h3>

        <div>
            <p>As expected, larger models(by parameter size) outperformed their smaller counterparts in the ADR detection task within their respective families,with Claude3 Opus achieving the highest accuracy at 77.41%, followed by GPT-4o and GPT-4Turbo at 72.03%. Interestingly, specialized medical models(OpenBioLLM-Llama3-70B and Llama3Med42v2-70B)struggled in this task. However, for ADR multiclass classification,we did not observe any clear pattern between model size and performance. GPT-4 Turbo was the best performing model with an accuracy of 57.58%, followed by Llama3-Med42v2-70B at 56.40%. All models struggled with multiclass classification,likely due to the complexity of distinguishing between ADR types.</p>
        </div>

        <footer>
            &copy; 2024 ADR Paper Blog. All rights reserved.
        </footer>
    </div>
</body>
</html>
