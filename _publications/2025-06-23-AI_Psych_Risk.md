---
title: 'From Lived Experience to Insight: Unpacking the Psychological Risks of Using AI Conversational Agents'
collection: publications
permalink: /publication/2025-06-23-AI_Psych_Risk
abstract: 'Recent gains in popularity of AI conversational agents have led to their increased use for improving productivity and supporting well-being. While previous research has aimed to understand the risks associated with interactions with AI conversational agents, these studies often fall short in capturing the lived experiences of individuals. Additionally, psychological risks have often been presented as a sub-category within broader AI-related risks in past taxonomy works, leading to under-representation of the impact of psychological risks of AI use. To address these challenges, our work presents a novel risk taxonomy focusing on psychological risks of using AI gathered through the lived experiences of individuals. We employed a mixed-method approach, involving a comprehensive survey with 283 people with lived mental health experience and workshops involving experts with lived experience to develop a psychological risk taxonomy. Our taxonomy features 19 AI behaviors, 21 negative psychological impacts, and 15 contexts related to individuals. Additionally, we propose a novel multi-path vignette-based framework for understanding the complex interplay between AI behaviors, psychological impacts, and individual user contexts. Finally, based on the feedback obtained from the workshop sessions, we present design recommendations for developing safer and more robust AI agents. Our work offers an in-depth understanding of the psychological risks associated with AI conversational agents and provides actionable recommendations for policymakers, researchers, and developers.'
date: '23-06-2025'
venue: 'Proceedings of the 2025 ACM Conference on Fairness, Accountability, and Transparency (FAccT 2025)'
paperurl: 'https://dl.acm.org/doi/10.1145/3715275.3732063'
paperfile: http://mohit3011.github.io/files/llm_adr_paper.pdf
authors: '<b>Mohit Chandra</b>, Suchismita Naik, Denae Ford, Ebele Okoli, Munmun De Choudhury, Mahsa Ershadi, Gonzalo Ramos, Javier Hernandez, Ananya Bhattacharjee, Shahed Warreth, Jina Suh'
citation: '@inproceedings{10.1145/3715275.3732063,
author = {Chandra, Mohit and Naik, Suchismita and Ford, Denae and Okoli, Ebele and De Choudhury, Munmun and Ershadi, Mahsa and Ramos, Gonzalo and Hernandez, Javier and Bhattacharjee, Ananya and Warreth, Shahed and Suh, Jina},
title = {From Lived Experience to Insight: Unpacking the Psychological Risks of Using AI Conversational Agents},
year = {2025},
isbn = {9798400714825},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3715275.3732063},
doi = {10.1145/3715275.3732063},
abstract = {Recent gains in popularity of AI conversational agents have led to their increased use for improving productivity and supporting well-being. While previous research has aimed to understand the risks associated with interactions with AI conversational agents, these studies often fall short in capturing the lived experiences of individuals. Additionally, psychological risks have often been presented as a sub-category within broader AI-related risks in past taxonomy works, leading to under-representation of the impact of psychological risks of AI use. To address these challenges, our work presents a novel risk taxonomy focusing on psychological risks of using AI gathered through the lived experiences of individuals. We employed a mixed-method approach, involving a comprehensive survey with 283 people with lived mental health experience and workshops involving experts with lived experience to develop a psychological risk taxonomy. Our taxonomy features 19 AI behaviors, 21 negative psychological impacts, and 15 contexts related to individuals. Additionally, we propose a novel multi-path vignette-based framework for understanding the complex interplay between AI behaviors, psychological impacts, and individual user contexts. Finally, based on the feedback obtained from the workshop sessions, we present design recommendations for developing safer and more robust AI agents. Our work offers an in-depth understanding of the psychological risks associated with AI conversational agents and provides actionable recommendations for policymakers, researchers, and developers.Content Warning: This paper includes discussions of sensitive topics, including but not limited to self-harm, body shaming, and discrimination.},
booktitle = {Proceedings of the 2025 ACM Conference on Fairness, Accountability, and Transparency},
pages = {975â€“1004},
numpages = {30},
keywords = {AI, Psychological risks, Psychological risk taxonomy, Lived experience},
location = {
},
series = {FAccT '25}
}'
---
